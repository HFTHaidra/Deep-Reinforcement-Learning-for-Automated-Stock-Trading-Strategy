{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AmineV250.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "V8_namfrWOg9",
        "E4pj1K8_WOiU"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8_namfrWOg9"
      },
      "source": [
        "> 1. > # HyperParameter\n",
        "***DRL for stock trading*:**\n",
        "Deep Reinforcement Learning for Automated Stock Trading\n",
        "Using reinforcement learning to trade multiple stocks through Python and OpenAI Gym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzyorWIRWOhe"
      },
      "source": [
        "#from google.colab import drive ; drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SB58R8WOhf",
        "outputId": "26bb6438-720f-4884-bb3e-ea9bf3b10750"
      },
      "source": [
        "!pip install gym keras keras-rl2 tensorflow==2.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 keras-rl2-1.0.4 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltZWqNRRWOhl",
        "outputId": "053c96ac-6804-4d8d-d4fe-f41404daf94b"
      },
      "source": [
        "from numpy import loadtxt\n",
        "import os\n",
        "#os.chdir(\"/content/drive/MyDrive\") \n",
        "\n",
        "\n",
        "#data = loadtxt('2010_2021.csv', delimiter=',' , encoding='utf-16') \n",
        "data = loadtxt('US30_from2021.csv', delimiter=',' , encoding='utf-16')\n",
        "prices = data[:,1]\n",
        "dates = data[:,0]\n",
        "dates = dates.astype(int)\n",
        "len(prices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "105869"
            ]
          },
          "execution_count": 2,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4pj1K8_WOiU"
      },
      "source": [
        "# Reloud AI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv6QpAZaI0jL"
      },
      "source": [
        "\n",
        "import pandas as pd \n",
        "from datetime import datetime as dt\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from numpy import savetxt\n",
        "import random ; from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense , Flatten \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from rl.policy import * ; from rl.memory import * ; from rl.agents import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZgFXuXRI0jM"
      },
      "source": [
        "#input_shape=(Memoryin_window_length,ob_space_Length,window)\n",
        "Memoryin_window_length      = 1\n",
        "window                      = 360\n",
        "ob_space_Length             = 5\n",
        "actions                     = 3\n",
        "MemoryLimit                 = 600000\n",
        "#----------------------------------------------------------- \n",
        "fee                         = 3.0\n",
        "SL                          = 25.0\n",
        "TP                          = 25.0\n",
        "#------------------------------------------------------------\n",
        "Time_each_trade             = 60\n",
        "\n",
        "#------------------------------------------------------------\n",
        "steps = 1000\n",
        "Looping = 2\n",
        "sIndex                        = 4000\n",
        "eIndex                        = 3200000    # MAX = 3.490.000 [ 290.000 Traning 200 Evalation]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOJKPbJjI0jM",
        "outputId": "3aa2e79a-f820-43f2-d5eb-ddb415aee9db"
      },
      "source": [
        "360/8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "45.0"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsSA8uBthgH7"
      },
      "source": [
        "def GrapheV15(stats):\n",
        "    plt.figure(figsize=(16, 9)) \n",
        "    x = stats[:,0]\n",
        "    y = np.arange(0,len(x) ) \n",
        "    plt.plot(  y ,   x   , label=\"US30 Line\" )\n",
        "    plt.plot(  y ,  stats[:,1]    , label=\"US30 Line\" )\n",
        "    plt.plot(  y ,  stats[:,2]    , label=\"US30 Line\" )\n",
        "    plt.plot(  y ,  stats[:,3]    , label=\"US30 Line\" )\n",
        "    plt.plot(  y ,  stats[:,4]    , label=\"US30 Line\" )\n",
        "    plt.show()\n",
        "def GrapheV16(price):\n",
        "    plt.figure(figsize=(16, 9)) \n",
        "    x = price\n",
        "    y = np.arange(0,len(x) ) \n",
        "    plt.plot(  y ,   x   , label=\"US30 Line\" )\n",
        "    plt.show()    \n",
        "def showV409(nb):\n",
        "  x = []\n",
        "  y = []\n",
        "  p = 0\n",
        "  s = 0\n",
        "  for i in range(0, len(env.R)  ):\n",
        "    for j in range( 0 , len(env.R[i])   ):\n",
        "      s = s + env.R[i][j]\n",
        "      if ( env.R[i][j] != 0 ):\n",
        "        x.append(s)\n",
        "        y.append(p)\n",
        "        p = p + 1\n",
        "  k = nb\n",
        "  l = 0\n",
        "  print( ' All Rewards : {} \\n'.format(  x[ len(x)-1 ]  ) )\n",
        "  for i in range(0,k):\n",
        "    m = int (len(x)/k )\n",
        "    x1 = x[ l:(m + m*i) ]\n",
        "    y1 = y[ l:(m + m*i) ]\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    plt.plot( y1, x1, label=\"US30 Line\") \n",
        "    plt.xlabel(\"x axis\")\n",
        "    plt.ylabel(\"y axis\")\n",
        "    plt.title(\"Line Graph Example\")\n",
        "    plt.show()  # 200\n",
        "    l = (m + m*i)    \n",
        "def ShowReward(nb,AllReward):\n",
        "  x = []\n",
        "  y = []\n",
        "  p = 0\n",
        "  s = 0\n",
        "  for i in range(0, len(AllReward)  ):\n",
        "    if ( AllReward[i] != 0 ):\n",
        "      s+=AllReward[i]\n",
        "      x.append(s)\n",
        "      y.append(p)\n",
        "      p = p + 1\n",
        "  k = nb\n",
        "  l = 0\n",
        "  if(len(x)>2):\n",
        "    print( ' All Rewards : {} \\n'.format(  x[ len(x)-1 ]  ) )\n",
        "  for i in range(0,k):\n",
        "    m = int (len(x)/k )\n",
        "    x1 = x[ l:(m + m*i) ]\n",
        "    y1 = y[ l:(m + m*i) ]\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    plt.plot( y1, x1, label=\"US30 Line\") \n",
        "    plt.xlabel(\"x axis\")\n",
        "    plt.ylabel(\"y axis\")\n",
        "    plt.title(\"Line Graph Example\")\n",
        "    plt.show()  # 200\n",
        "    l = (m + m*i)         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4wUU7NdYjqf",
        "outputId": "b1f0d084-16f9-4fed-f083-084442d18e9f"
      },
      "source": [
        "def build_model(ob_space_Length, window, actions,Memoryin_window_length):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128,activation='relu', input_shape=(Memoryin_window_length,ob_space_Length,window) ) )\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(actions))\n",
        "    return model    \n",
        "def build_agent(model, actions,Memoryin_window_length):\n",
        "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.2, nb_steps=10000)\n",
        "    memory = SequentialMemory(limit= MemoryLimit , window_length=Memoryin_window_length)\n",
        "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
        "                  enable_dueling_network=True, dueling_type='avg', \n",
        "                   nb_actions=actions, nb_steps_warmup=1000 ,\n",
        "                   gamma=0.95 \n",
        "                  )\n",
        "    return dqn  \n",
        "model = build_model(ob_space_Length, window, actions,Memoryin_window_length)\n",
        "model.summary()\n",
        "dqn = build_agent(model, actions,Memoryin_window_length)\n",
        "dqn.compile( Adam(lr=1e-4))    \n",
        "#name  = 'WSaved/17-36-20/17-36-20.h5f'\n",
        "#dqn.load_weights(name)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1, 5, 128)         46208     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1, 5, 256)         33024     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1, 5, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1, 5, 128)         32896     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 640)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 1923      \n",
            "=================================================================\n",
            "Total params: 179,843\n",
            "Trainable params: 179,843\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1dyCqVDWx7t"
      },
      "source": [
        "def isShort( indexStart ):\n",
        "  global prices , TP , SL , fee\n",
        "  res = -1\n",
        "  index = 1 #min + random.randint(0, 3)\n",
        "  min = indexStart\n",
        "  max = min+ 4000\n",
        "  for i in range(min,max):\n",
        "    if( prices[i] <= (prices[min]-TP) ):\n",
        "      res = TP - fee\n",
        "      index = i - min  \n",
        "      break\n",
        "    if( prices[i] >= (prices[min]+SL) ):\n",
        "      res = -SL \n",
        "      index = i - min    \n",
        "      break\n",
        "  if( res == -1 ):\n",
        "    print(\"XLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLX\")  \n",
        "    res = -SL -fee\n",
        "    index = max - min\n",
        "  return [res , index]\n",
        "def isLong( indexStart ):\n",
        "  global prices , TP , SL , fee\n",
        "  res = -1\n",
        "  index = 1 #min + random.randint(1, 3)\n",
        "  min = indexStart\n",
        "  max = min+ 4000\n",
        "  for i in range(min,max):\n",
        "    if( prices[i] >= (prices[min]+TP) ):\n",
        "      res = TP - fee\n",
        "      index = i - min   \n",
        "      break\n",
        "    if( prices[i] <= (prices[min]-SL) ):\n",
        "      res = -SL \n",
        "      index = i - min   \n",
        "      break\n",
        "  if( res == -1 ):\n",
        "    print(\"XLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLXLX\")  \n",
        "    res = -SL -fee\n",
        "    index = max - min\n",
        "  return [res , index]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJKqaQ_UURkx"
      },
      "source": [
        "def SMAOLD(Data,Periodes):\n",
        "    n = len(Data)-1 \n",
        "    res = [Data[0]]\n",
        "    for i in range(0,n):\n",
        "      iSMA = 0\n",
        "      for j in range(i,i+Periodes):\n",
        "        if(j>=n):\n",
        "          iSMA = iSMA +Data[n]\n",
        "        else:\n",
        "          iSMA = iSMA + Data[j]\n",
        "      iSMA = iSMA/Periodes  \n",
        "      res.append(iSMA)\n",
        "    return res \n",
        "def getStats(price_):\n",
        "  res  = []\n",
        "  sma5 =  SMAOLD( price_, 5  )\n",
        "  sma10 = SMAOLD( price_, 10 )\n",
        "  sma20 = SMAOLD( price_, 20 )\n",
        "  sma50 = SMAOLD( price_, 50 )\n",
        "  for i in range(0,len(price_)):\n",
        "    res.append( [ price_[i] ,sma5[i],sma10[i],sma20[i],sma50[i]  ] )\n",
        "  res     = np.array(res)  \n",
        "  #ma = res.max()\n",
        "  #mi = res.min()\n",
        "  ma = price_[0]+1000\n",
        "  mi = price_[0]-1000\n",
        "  #print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~>{} '.format(ma-mi ) )\n",
        "  res = ( res - mi )/(ma - mi) \n",
        "  #print( ' ~~~~~~~~~~~~~~~ Max = {} _ Min = {} '.format(res.max(),  res.min() ) )\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "flZRsFfStD_H",
        "outputId": "0ff6c0dd-ed17-4c4c-991e-a7616d21752c"
      },
      "source": [
        "class env1(Env ):\n",
        "    def __init__(self,  prices  ,tp_,sl_, ifTesting):\n",
        "         #------------  observation_space  observation_space --------------------------------------------\n",
        "        global ob_space_Length , window  , fee , sIndex , eIndex , Time_each_trade , AllReward\n",
        "        self.window = window   # 360Min = 6H (Best View) \n",
        "        self.prices = prices\n",
        "        self.observation_space = Box(low= 0.0, high= 1.0, shape=( ob_space_Length ,self.window), dtype=np.float64 )\n",
        "        self.action_space = Discrete(3)\n",
        " \n",
        "        #------------  Parameters --------------------------------------------\n",
        "        self.DayStep =  360 #1380\n",
        "        self.startIndex = sIndex\n",
        "        self.iwin = 0               # iWindow [ 0 - (length_data - window ) ]\n",
        "        self.SL = sl_\n",
        "        self.TP = tp_\n",
        "        self.ifTesting = ifTesting\n",
        "        self.Time_each_trade = Time_each_trade\n",
        "\n",
        " \n",
        " \n",
        "    def step(self, action):\n",
        "        reward = 0\n",
        "        \n",
        "        iaccPrice = self.startIndex  + self.iwin\n",
        "        \n",
        "        accPrice = self.prices[iaccPrice]\n",
        "        newprice = 0\n",
        "        \n",
        "        if(action==0):# sell\n",
        "          reward , index = isShort( iaccPrice  )\n",
        "\n",
        "          \n",
        "        \n",
        "        if(action==1):# Buy\n",
        "          reward , index = isLong( iaccPrice  )\n",
        "\n",
        "           \n",
        "        if(action==2):# none\n",
        "          reward = 0.01\n",
        " \n",
        "        self.iwin = self.iwin + self.Time_each_trade  # 60 1H\n",
        "        \n",
        "        # Check if shower is done\n",
        "        if self.iwin > ( len(self.DayStats)  ) :\n",
        "            done = True\n",
        "           \n",
        "           \n",
        "        else:\n",
        "            done = False\n",
        "            i1 = self.iwin - self.window\n",
        "            i2 = self.iwin\n",
        "            self.state = np.transpose( self.DayStats[i1:i2] )\n",
        "            #print( '--->{}  '.format( self.iwin  ) )\n",
        "            \n",
        "            \n",
        "        info_ = {}\n",
        "        AllReward.append( reward )\n",
        "        return self.state, reward, done, info_\n",
        " \n",
        "    def render(self):\n",
        "       r=0\n",
        "         \n",
        "    def reset(self):\n",
        "        self.iwin = self.window\n",
        "        self.startIndex += self.DayStep + random.randint(0, 50) \n",
        "        d1 = self.startIndex\n",
        "        d2 = d1 + self.DayStep \n",
        "        self.DayStats  = getStats( prices[d1:d2] )\n",
        "        \n",
        "        i1 = self.iwin - self.window\n",
        "        i2 = self.iwin\n",
        "        \n",
        "        self.state = np.transpose( self.DayStats[i1:i2]  )\n",
        "        #print('---------------> {} <--------------'.format( d2 ))\n",
        "        if( d2 > eIndex  ):\n",
        "          self.startIndex = sIndex + random.randint(0, 50) \n",
        "\n",
        "        return self.state\n",
        "#-----------------------------------------------------------------\n",
        "AllReward = []\n",
        "sIndex                        = 0\n",
        "eIndex                        = 500000\n",
        "env = env1(    prices , TP, SL,1)\n",
        "_ = dqn.test(env, nb_episodes=100  , visualize=False)\n",
        "\n",
        "ShowReward(1,AllReward)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for 100 episodes ...\n",
            "---------------> 738 <--------------\n",
            "Episode 1: reward: 22.000, steps: 1\n",
            "---------------> 1119 <--------------\n",
            "Episode 2: reward: 0.010, steps: 1\n",
            "---------------> 1498 <--------------\n",
            "Episode 3: reward: 22.000, steps: 1\n",
            "---------------> 1878 <--------------\n",
            "Episode 4: reward: 0.010, steps: 1\n",
            "---------------> 2260 <--------------\n",
            "Episode 5: reward: 0.010, steps: 1\n",
            "---------------> 2630 <--------------\n",
            "Episode 6: reward: 22.000, steps: 1\n",
            "---------------> 3017 <--------------\n",
            "Episode 7: reward: 0.010, steps: 1\n",
            "---------------> 3394 <--------------\n",
            "Episode 8: reward: 22.000, steps: 1\n",
            "---------------> 3757 <--------------\n",
            "Episode 9: reward: 22.000, steps: 1\n",
            "---------------> 4136 <--------------\n",
            "Episode 10: reward: 0.010, steps: 1\n",
            "---------------> 4517 <--------------\n",
            "Episode 11: reward: -25.000, steps: 1\n",
            "---------------> 4890 <--------------\n",
            "Episode 12: reward: 0.010, steps: 1\n",
            "---------------> 5282 <--------------\n",
            "Episode 13: reward: 22.000, steps: 1\n",
            "---------------> 5686 <--------------\n",
            "Episode 14: reward: 22.000, steps: 1\n",
            "---------------> 6068 <--------------\n",
            "Episode 15: reward: -25.000, steps: 1\n",
            "---------------> 6438 <--------------\n",
            "Episode 16: reward: 0.010, steps: 1\n",
            "---------------> 6844 <--------------\n",
            "Episode 17: reward: -25.000, steps: 1\n",
            "---------------> 7219 <--------------\n",
            "Episode 18: reward: 22.000, steps: 1\n",
            "---------------> 7615 <--------------\n",
            "Episode 19: reward: 0.010, steps: 1\n",
            "---------------> 8000 <--------------\n",
            "Episode 20: reward: 22.000, steps: 1\n",
            "---------------> 8397 <--------------\n",
            "Episode 21: reward: 22.000, steps: 1\n",
            "---------------> 8789 <--------------\n",
            "Episode 22: reward: -25.000, steps: 1\n",
            "---------------> 9150 <--------------\n",
            "Episode 23: reward: 0.010, steps: 1\n",
            "---------------> 9518 <--------------\n",
            "Episode 24: reward: 22.000, steps: 1\n",
            "---------------> 9908 <--------------\n",
            "Episode 25: reward: 22.000, steps: 1\n",
            "---------------> 10287 <--------------\n",
            "Episode 26: reward: 0.010, steps: 1\n",
            "---------------> 10663 <--------------\n",
            "Episode 27: reward: 22.000, steps: 1\n",
            "---------------> 11032 <--------------\n",
            "Episode 28: reward: 0.010, steps: 1\n",
            "---------------> 11425 <--------------\n",
            "Episode 29: reward: 0.010, steps: 1\n",
            "---------------> 11792 <--------------\n",
            "Episode 30: reward: 0.010, steps: 1\n",
            "---------------> 12167 <--------------\n",
            "Episode 31: reward: 0.010, steps: 1\n",
            "---------------> 12565 <--------------\n",
            "Episode 32: reward: 0.010, steps: 1\n",
            "---------------> 12933 <--------------\n",
            "Episode 33: reward: 0.010, steps: 1\n",
            "---------------> 13297 <--------------\n",
            "Episode 34: reward: 22.000, steps: 1\n",
            "---------------> 13704 <--------------\n",
            "Episode 35: reward: 0.010, steps: 1\n",
            "---------------> 14078 <--------------\n",
            "Episode 36: reward: 0.010, steps: 1\n",
            "---------------> 14454 <--------------\n",
            "Episode 37: reward: 0.010, steps: 1\n",
            "---------------> 14846 <--------------\n",
            "Episode 38: reward: 22.000, steps: 1\n",
            "---------------> 15241 <--------------\n",
            "Episode 39: reward: 0.010, steps: 1\n",
            "---------------> 15638 <--------------\n",
            "Episode 40: reward: 22.000, steps: 1\n",
            "---------------> 16036 <--------------\n",
            "Episode 41: reward: -25.000, steps: 1\n",
            "---------------> 16433 <--------------\n",
            "Episode 42: reward: 0.010, steps: 1\n",
            "---------------> 16810 <--------------\n",
            "Episode 43: reward: -25.000, steps: 1\n",
            "---------------> 17177 <--------------\n",
            "Episode 44: reward: -25.000, steps: 1\n",
            "---------------> 17547 <--------------\n",
            "Episode 45: reward: 22.000, steps: 1\n",
            "---------------> 17954 <--------------\n",
            "Episode 46: reward: 0.010, steps: 1\n",
            "---------------> 18336 <--------------\n",
            "Episode 47: reward: -25.000, steps: 1\n",
            "---------------> 18697 <--------------\n",
            "Episode 48: reward: -25.000, steps: 1\n",
            "---------------> 19077 <--------------\n",
            "Episode 49: reward: -25.000, steps: 1\n",
            "---------------> 19480 <--------------\n",
            "Episode 50: reward: 0.010, steps: 1\n",
            "---------------> 19870 <--------------\n",
            "Episode 51: reward: 22.000, steps: 1\n",
            "---------------> 20260 <--------------\n",
            "Episode 52: reward: 0.010, steps: 1\n",
            "---------------> 20641 <--------------\n",
            "Episode 53: reward: 0.010, steps: 1\n",
            "---------------> 21025 <--------------\n",
            "Episode 54: reward: -25.000, steps: 1\n",
            "---------------> 21432 <--------------\n",
            "Episode 55: reward: -25.000, steps: 1\n",
            "---------------> 21812 <--------------\n",
            "Episode 56: reward: 0.010, steps: 1\n",
            "---------------> 22217 <--------------\n",
            "Episode 57: reward: -25.000, steps: 1\n",
            "---------------> 22591 <--------------\n",
            "Episode 58: reward: 0.010, steps: 1\n",
            "---------------> 22958 <--------------\n",
            "Episode 59: reward: 0.010, steps: 1\n",
            "---------------> 23358 <--------------\n",
            "Episode 60: reward: 22.000, steps: 1\n",
            "---------------> 23738 <--------------\n",
            "Episode 61: reward: -25.000, steps: 1\n",
            "---------------> 24144 <--------------\n",
            "Episode 62: reward: 0.010, steps: 1\n",
            "---------------> 24508 <--------------\n",
            "Episode 63: reward: 22.000, steps: 1\n",
            "---------------> 24899 <--------------\n",
            "Episode 64: reward: 0.010, steps: 1\n",
            "---------------> 25305 <--------------\n",
            "Episode 65: reward: 22.000, steps: 1\n",
            "---------------> 25699 <--------------\n",
            "Episode 66: reward: 22.000, steps: 1\n",
            "---------------> 26096 <--------------\n",
            "Episode 67: reward: -25.000, steps: 1\n",
            "---------------> 26470 <--------------\n",
            "Episode 68: reward: -25.000, steps: 1\n",
            "---------------> 26859 <--------------\n",
            "Episode 69: reward: 22.000, steps: 1\n",
            "---------------> 27265 <--------------\n",
            "Episode 70: reward: 22.000, steps: 1\n",
            "---------------> 27638 <--------------\n",
            "Episode 71: reward: -25.000, steps: 1\n",
            "---------------> 28040 <--------------\n",
            "Episode 72: reward: 22.000, steps: 1\n",
            "---------------> 28404 <--------------\n",
            "Episode 73: reward: -25.000, steps: 1\n",
            "---------------> 28789 <--------------\n",
            "Episode 74: reward: 22.000, steps: 1\n",
            "---------------> 29184 <--------------\n",
            "Episode 75: reward: 22.000, steps: 1\n",
            "---------------> 29586 <--------------\n",
            "Episode 76: reward: 22.000, steps: 1\n",
            "---------------> 29977 <--------------\n",
            "Episode 77: reward: 0.010, steps: 1\n",
            "---------------> 30378 <--------------\n",
            "Episode 78: reward: 0.010, steps: 1\n",
            "---------------> 30738 <--------------\n",
            "Episode 79: reward: 0.010, steps: 1\n",
            "---------------> 31109 <--------------\n",
            "Episode 80: reward: 0.010, steps: 1\n",
            "---------------> 31489 <--------------\n",
            "Episode 81: reward: 0.010, steps: 1\n",
            "---------------> 31866 <--------------\n",
            "Episode 82: reward: 22.000, steps: 1\n",
            "---------------> 32240 <--------------\n",
            "Episode 83: reward: 0.010, steps: 1\n",
            "---------------> 32615 <--------------\n",
            "Episode 84: reward: 22.000, steps: 1\n",
            "---------------> 33019 <--------------\n",
            "Episode 85: reward: 0.010, steps: 1\n",
            "---------------> 33413 <--------------\n",
            "Episode 86: reward: -25.000, steps: 1\n",
            "---------------> 33784 <--------------\n",
            "Episode 87: reward: -25.000, steps: 1\n",
            "---------------> 34144 <--------------\n",
            "Episode 88: reward: 22.000, steps: 1\n",
            "---------------> 34514 <--------------\n",
            "Episode 89: reward: 0.010, steps: 1\n",
            "---------------> 34912 <--------------\n",
            "Episode 90: reward: 22.000, steps: 1\n",
            "---------------> 35286 <--------------\n",
            "Episode 91: reward: -25.000, steps: 1\n",
            "---------------> 35675 <--------------\n",
            "Episode 92: reward: 0.010, steps: 1\n",
            "---------------> 36045 <--------------\n",
            "Episode 93: reward: 0.010, steps: 1\n",
            "---------------> 36409 <--------------\n",
            "Episode 94: reward: 22.000, steps: 1\n",
            "---------------> 36779 <--------------\n",
            "Episode 95: reward: 0.010, steps: 1\n",
            "---------------> 37180 <--------------\n",
            "Episode 96: reward: 0.010, steps: 1\n",
            "---------------> 37554 <--------------\n",
            "Episode 97: reward: 22.000, steps: 1\n",
            "---------------> 37940 <--------------\n",
            "Episode 98: reward: 22.000, steps: 1\n",
            "---------------> 38348 <--------------\n",
            "Episode 99: reward: 0.010, steps: 1\n",
            "---------------> 38714 <--------------\n",
            "Episode 100: reward: 0.010, steps: 1\n",
            " All Rewards : 245.43999999999977 \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsV3M__m26K-"
      },
      "source": [
        " #ShowReward(4,AllReward)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "2beYwoC3Wy78",
        "outputId": "4a612ea2-8cfb-436c-bde5-5b5e05f150c0"
      },
      "source": [
        "AllReward = []\n",
        "sIndex                        = 3300000\n",
        "eIndex                        = 3400000\n",
        "env = env1(prices , TP, SL,1)\n",
        "_ = dqn.test(env, nb_episodes=10  , visualize=False)\n",
        " \n",
        "ShowReward(1,AllReward)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for 10 episodes ...\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b33f09b8d5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meIndex\u001b[0m                        \u001b[0;34m=\u001b[0m \u001b[0;36m3400000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mTP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mShowReward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAllReward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rl/core.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, env, nb_episodes, action_repetition, callbacks, visualize, nb_max_episode_steps, nb_max_start_steps, start_step_policy, verbose)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;31m# Obtain the initial observation by resetting the environment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-d50f9d220e66>\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDayStep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDayStats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mgetStats\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miwin\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7281b98e079f>\u001b[0m in \u001b[0;36mgetStats\u001b[0;34m(price_)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mres\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0msma5\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mSMAOLD\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mprice_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0msma10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMAOLD\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mprice_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0msma20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMAOLD\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mprice_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7281b98e079f>\u001b[0m in \u001b[0;36mSMAOLD\u001b[0;34m(Data, Periodes)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mSMAOLD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPeriodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0miSMA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbvVSonxI0jT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyLs1bLPYGKg",
        "outputId": "4b911ae8-efbe-4c5f-d630-98acd2bb9260"
      },
      "source": [
        "100000/60/23/20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.6231884057971016"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-Qa_kU4b_9g",
        "scrolled": true,
        "outputId": "8afc847e-4673-4549-9dc2-4840fb589eb1"
      },
      "source": [
        "#  hjgh\n",
        "sIndex                        = 0\n",
        "eIndex                        = 50000\n",
        "env = env1(    prices , TP, SL,0)\n",
        "FileVersion = \"K/Aminev250/\"\n",
        "time = datetime.now()\n",
        "time = time.strftime(\"%H-%M-%S\")\n",
        "render = 0\n",
        "steps = 400000\n",
        "Looping = 1\n",
        "NameSaving = \"testing\"\n",
        "for i in range(0,Looping):\n",
        "  dqn.fit(env, nb_steps=steps, visualize=False, verbose=2)\n",
        "  time_ = datetime.now()\n",
        "  time_ qqqqqq= time_.strftime(\"%H-%M-%S\")\n",
        "  NameSaving = FileVersion+time_+'/' +str(time_)+\".h5f\"\n",
        "  print('IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII') \n",
        "  print(NameSaving)\n",
        "  print('IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII')\n",
        "  dqn.save_weights(NameSaving, overwrite=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  43131/400000: episode: 43131, duration: 0.061s, episode steps:   1, steps per second:  16, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 107.937973, mean_q: 3.265139, mean_eps: 0.100000\n",
            "  43132/400000: episode: 43132, duration: 0.048s, episode steps:   1, steps per second:  21, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 92.010933, mean_q: 3.389651, mean_eps: 0.100000\n",
            "  43133/400000: episode: 43133, duration: 0.044s, episode steps:   1, steps per second:  23, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 80.717499, mean_q: 3.431104, mean_eps: 0.100000\n",
            "  43134/400000: episode: 43134, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 105.851593, mean_q: 2.701857, mean_eps: 0.100000\n",
            "  43135/400000: episode: 43135, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 138.340210, mean_q: 2.711573, mean_eps: 0.100000\n",
            "  43136/400000: episode: 43136, duration: 0.062s, episode steps:   1, steps per second:  16, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 99.401558, mean_q: 2.607915, mean_eps: 0.100000\n",
            "  43137/400000: episode: 43137, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 121.505615, mean_q: 3.299535, mean_eps: 0.100000\n",
            "  43138/400000: episode: 43138, duration: 0.051s, episode steps:   1, steps per second:  19, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 96.925095, mean_q: 4.380981, mean_eps: 0.100000\n",
            "  43139/400000: episode: 43139, duration: 0.050s, episode steps:   1, steps per second:  20, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 154.553040, mean_q: 2.772959, mean_eps: 0.100000\n",
            "  43140/400000: episode: 43140, duration: 0.053s, episode steps:   1, steps per second:  19, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 126.875725, mean_q: 2.211388, mean_eps: 0.100000\n",
            "  43141/400000: episode: 43141, duration: 0.060s, episode steps:   1, steps per second:  17, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 157.859299, mean_q: 2.279361, mean_eps: 0.100000\n",
            "  43142/400000: episode: 43142, duration: 0.048s, episode steps:   1, steps per second:  21, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 1.000 [1.000, 1.000],  loss: 119.594009, mean_q: 2.882693, mean_eps: 0.100000\n",
            "  43143/400000: episode: 43143, duration: 0.041s, episode steps:   1, steps per second:  24, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 1.000 [1.000, 1.000],  loss: 80.102318, mean_q: 3.280337, mean_eps: 0.100000\n",
            "  43144/400000: episode: 43144, duration: 0.043s, episode steps:   1, steps per second:  23, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 0.000 [0.000, 0.000],  loss: 100.706161, mean_q: 2.678006, mean_eps: 0.100000\n",
            "  43145/400000: episode: 43145, duration: 0.059s, episode steps:   1, steps per second:  17, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 143.286652, mean_q: 3.090288, mean_eps: 0.100000\n",
            "  43146/400000: episode: 43146, duration: 0.055s, episode steps:   1, steps per second:  18, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 113.415077, mean_q: 5.591163, mean_eps: 0.100000\n",
            "  43147/400000: episode: 43147, duration: 0.043s, episode steps:   1, steps per second:  23, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 193.795929, mean_q: 3.974811, mean_eps: 0.100000\n",
            "  43148/400000: episode: 43148, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 128.619476, mean_q: 4.141768, mean_eps: 0.100000\n",
            "  43149/400000: episode: 43149, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 102.072578, mean_q: 3.398913, mean_eps: 0.100000\n",
            "  43150/400000: episode: 43150, duration: 0.061s, episode steps:   1, steps per second:  16, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 94.023163, mean_q: 2.939965, mean_eps: 0.100000\n",
            "  43151/400000: episode: 43151, duration: 0.043s, episode steps:   1, steps per second:  23, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 0.000 [0.000, 0.000],  loss: 118.071022, mean_q: 4.106471, mean_eps: 0.100000\n",
            "  43152/400000: episode: 43152, duration: 0.044s, episode steps:   1, steps per second:  23, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 129.317627, mean_q: 2.278646, mean_eps: 0.100000\n",
            "  43153/400000: episode: 43153, duration: 0.041s, episode steps:   1, steps per second:  24, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 134.225571, mean_q: 2.321835, mean_eps: 0.100000\n",
            "  43154/400000: episode: 43154, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 91.847221, mean_q: 2.837979, mean_eps: 0.100000\n",
            "  43155/400000: episode: 43155, duration: 0.060s, episode steps:   1, steps per second:  17, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 97.708076, mean_q: 2.700199, mean_eps: 0.100000\n",
            "  43156/400000: episode: 43156, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 86.748474, mean_q: 3.969149, mean_eps: 0.100000\n",
            "  43157/400000: episode: 43157, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 121.893883, mean_q: 2.192209, mean_eps: 0.100000\n",
            "  43158/400000: episode: 43158, duration: 0.049s, episode steps:   1, steps per second:  20, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 1.000 [1.000, 1.000],  loss: 75.520996, mean_q: 2.949812, mean_eps: 0.100000\n",
            "  43159/400000: episode: 43159, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 121.931343, mean_q: 3.241446, mean_eps: 0.100000\n",
            "  43160/400000: episode: 43160, duration: 0.064s, episode steps:   1, steps per second:  16, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 0.000 [0.000, 0.000],  loss: 132.041290, mean_q: 2.634992, mean_eps: 0.100000\n",
            "  43161/400000: episode: 43161, duration: 0.053s, episode steps:   1, steps per second:  19, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 165.568680, mean_q: 3.955408, mean_eps: 0.100000\n",
            "  43162/400000: episode: 43162, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 130.999237, mean_q: 2.403374, mean_eps: 0.100000\n",
            "  43163/400000: episode: 43163, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 163.633438, mean_q: 3.052641, mean_eps: 0.100000\n",
            "  43164/400000: episode: 43164, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 90.739983, mean_q: 2.799252, mean_eps: 0.100000\n",
            "  43165/400000: episode: 43165, duration: 0.055s, episode steps:   1, steps per second:  18, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 144.296280, mean_q: 2.062558, mean_eps: 0.100000\n",
            "  43166/400000: episode: 43166, duration: 0.045s, episode steps:   1, steps per second:  22, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 1.000 [1.000, 1.000],  loss: 84.767136, mean_q: 3.160921, mean_eps: 0.100000\n",
            "  43167/400000: episode: 43167, duration: 0.054s, episode steps:   1, steps per second:  19, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 75.377945, mean_q: 2.749072, mean_eps: 0.100000\n",
            "  43168/400000: episode: 43168, duration: 0.048s, episode steps:   1, steps per second:  21, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 178.960968, mean_q: 3.966409, mean_eps: 0.100000\n",
            "  43169/400000: episode: 43169, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 95.828712, mean_q: 3.125053, mean_eps: 0.100000\n",
            "  43170/400000: episode: 43170, duration: 0.066s, episode steps:   1, steps per second:  15, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 101.442749, mean_q: 1.798319, mean_eps: 0.100000\n",
            "  43171/400000: episode: 43171, duration: 0.048s, episode steps:   1, steps per second:  21, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 127.456955, mean_q: 2.841236, mean_eps: 0.100000\n",
            "  43172/400000: episode: 43172, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 1.000 [1.000, 1.000],  loss: 136.744415, mean_q: 2.614358, mean_eps: 0.100000\n",
            "  43173/400000: episode: 43173, duration: 0.049s, episode steps:   1, steps per second:  20, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 130.194107, mean_q: 2.994857, mean_eps: 0.100000\n",
            "  43174/400000: episode: 43174, duration: 0.048s, episode steps:   1, steps per second:  21, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 113.077621, mean_q: 2.734979, mean_eps: 0.100000\n",
            "  43175/400000: episode: 43175, duration: 0.065s, episode steps:   1, steps per second:  15, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 183.024628, mean_q: 2.719707, mean_eps: 0.100000\n",
            "  43176/400000: episode: 43176, duration: 0.043s, episode steps:   1, steps per second:  23, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 1.000 [1.000, 1.000],  loss: 94.009880, mean_q: 2.027770, mean_eps: 0.100000\n",
            "  43177/400000: episode: 43177, duration: 0.044s, episode steps:   1, steps per second:  23, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 115.082924, mean_q: 3.283144, mean_eps: 0.100000\n",
            "  43178/400000: episode: 43178, duration: 0.043s, episode steps:   1, steps per second:  23, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 111.970543, mean_q: 4.126639, mean_eps: 0.100000\n",
            "  43179/400000: episode: 43179, duration: 0.045s, episode steps:   1, steps per second:  22, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 129.209534, mean_q: 3.077149, mean_eps: 0.100000\n",
            "  43180/400000: episode: 43180, duration: 0.058s, episode steps:   1, steps per second:  17, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 130.665848, mean_q: 3.279820, mean_eps: 0.100000\n",
            "  43181/400000: episode: 43181, duration: 0.050s, episode steps:   1, steps per second:  20, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 154.176071, mean_q: 4.723650, mean_eps: 0.100000\n",
            "  43182/400000: episode: 43182, duration: 0.044s, episode steps:   1, steps per second:  23, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 134.844177, mean_q: 3.266877, mean_eps: 0.100000\n",
            "  43183/400000: episode: 43183, duration: 0.044s, episode steps:   1, steps per second:  23, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 1.000 [1.000, 1.000],  loss: 102.289688, mean_q: 3.790727, mean_eps: 0.100000\n",
            "  43184/400000: episode: 43184, duration: 0.045s, episode steps:   1, steps per second:  22, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 131.922974, mean_q: 4.006838, mean_eps: 0.100000\n",
            "  43185/400000: episode: 43185, duration: 0.060s, episode steps:   1, steps per second:  17, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 99.453163, mean_q: 4.000313, mean_eps: 0.100000\n",
            "  43186/400000: episode: 43186, duration: 0.043s, episode steps:   1, steps per second:  23, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 101.365982, mean_q: 2.448856, mean_eps: 0.100000\n",
            "  43187/400000: episode: 43187, duration: 0.056s, episode steps:   1, steps per second:  18, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 1.000 [1.000, 1.000],  loss: 51.074135, mean_q: 3.237194, mean_eps: 0.100000\n",
            "  43188/400000: episode: 43188, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 135.017319, mean_q: 3.069572, mean_eps: 0.100000\n",
            "  43189/400000: episode: 43189, duration: 0.044s, episode steps:   1, steps per second:  23, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 0.000 [0.000, 0.000],  loss: 99.366043, mean_q: 2.738696, mean_eps: 0.100000\n",
            "  43190/400000: episode: 43190, duration: 0.067s, episode steps:   1, steps per second:  15, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 92.296288, mean_q: 4.326710, mean_eps: 0.100000\n",
            "  43191/400000: episode: 43191, duration: 0.043s, episode steps:   1, steps per second:  23, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 99.298111, mean_q: 4.062921, mean_eps: 0.100000\n",
            "  43192/400000: episode: 43192, duration: 0.042s, episode steps:   1, steps per second:  24, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 138.694275, mean_q: 2.833032, mean_eps: 0.100000\n",
            "  43193/400000: episode: 43193, duration: 0.044s, episode steps:   1, steps per second:  23, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 1.000 [1.000, 1.000],  loss: 94.260361, mean_q: 2.398179, mean_eps: 0.100000\n",
            "  43194/400000: episode: 43194, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 135.647552, mean_q: 2.939764, mean_eps: 0.100000\n",
            "  43195/400000: episode: 43195, duration: 0.061s, episode steps:   1, steps per second:  16, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 116.187256, mean_q: 2.937910, mean_eps: 0.100000\n",
            "  43196/400000: episode: 43196, duration: 0.045s, episode steps:   1, steps per second:  22, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 75.700943, mean_q: 3.222739, mean_eps: 0.100000\n",
            "  43197/400000: episode: 43197, duration: 0.049s, episode steps:   1, steps per second:  20, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 95.468155, mean_q: 3.587622, mean_eps: 0.100000\n",
            "  43198/400000: episode: 43198, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 119.067200, mean_q: 4.257917, mean_eps: 0.100000\n",
            "  43199/400000: episode: 43199, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 94.391563, mean_q: 4.297750, mean_eps: 0.100000\n",
            "  43200/400000: episode: 43200, duration: 0.065s, episode steps:   1, steps per second:  15, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 111.759781, mean_q: 3.323253, mean_eps: 0.100000\n",
            "  43201/400000: episode: 43201, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 100.569931, mean_q: 3.852962, mean_eps: 0.100000\n",
            "  43202/400000: episode: 43202, duration: 0.044s, episode steps:   1, steps per second:  22, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 192.101501, mean_q: 2.676534, mean_eps: 0.100000\n",
            "  43203/400000: episode: 43203, duration: 0.049s, episode steps:   1, steps per second:  20, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 101.115570, mean_q: 3.455958, mean_eps: 0.100000\n",
            "  43204/400000: episode: 43204, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 130.900970, mean_q: 5.017708, mean_eps: 0.100000\n",
            "  43205/400000: episode: 43205, duration: 0.065s, episode steps:   1, steps per second:  15, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 115.126900, mean_q: 3.663652, mean_eps: 0.100000\n",
            "  43206/400000: episode: 43206, duration: 0.045s, episode steps:   1, steps per second:  22, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 128.743683, mean_q: 3.344906, mean_eps: 0.100000\n",
            "  43207/400000: episode: 43207, duration: 0.050s, episode steps:   1, steps per second:  20, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 106.285934, mean_q: 2.751666, mean_eps: 0.100000\n",
            "  43208/400000: episode: 43208, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 175.403946, mean_q: 3.316848, mean_eps: 0.100000\n",
            "  43209/400000: episode: 43209, duration: 0.045s, episode steps:   1, steps per second:  22, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 0.000 [0.000, 0.000],  loss: 162.286316, mean_q: 3.169450, mean_eps: 0.100000\n",
            "  43210/400000: episode: 43210, duration: 0.055s, episode steps:   1, steps per second:  18, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 0.000 [0.000, 0.000],  loss: 136.795990, mean_q: 3.153671, mean_eps: 0.100000\n",
            "  43211/400000: episode: 43211, duration: 0.043s, episode steps:   1, steps per second:  23, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 102.207146, mean_q: 2.779380, mean_eps: 0.100000\n",
            "  43212/400000: episode: 43212, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 157.830048, mean_q: 3.144224, mean_eps: 0.100000\n",
            "  43213/400000: episode: 43213, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 93.087402, mean_q: 3.108722, mean_eps: 0.100000\n",
            "  43214/400000: episode: 43214, duration: 0.056s, episode steps:   1, steps per second:  18, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 1.000 [1.000, 1.000],  loss: 158.264069, mean_q: 2.004213, mean_eps: 0.100000\n",
            "  43215/400000: episode: 43215, duration: 0.061s, episode steps:   1, steps per second:  17, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 124.546265, mean_q: 3.386676, mean_eps: 0.100000\n",
            "  43216/400000: episode: 43216, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 79.491058, mean_q: 3.243889, mean_eps: 0.100000\n",
            "  43217/400000: episode: 43217, duration: 0.048s, episode steps:   1, steps per second:  21, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 105.203743, mean_q: 3.232826, mean_eps: 0.100000\n",
            "  43218/400000: episode: 43218, duration: 0.050s, episode steps:   1, steps per second:  20, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 99.460007, mean_q: 2.393745, mean_eps: 0.100000\n",
            "  43219/400000: episode: 43219, duration: 0.046s, episode steps:   1, steps per second:  22, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 146.151306, mean_q: 2.649799, mean_eps: 0.100000\n",
            "  43220/400000: episode: 43220, duration: 0.064s, episode steps:   1, steps per second:  16, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 121.822906, mean_q: 2.485956, mean_eps: 0.100000\n",
            "  43221/400000: episode: 43221, duration: 0.045s, episode steps:   1, steps per second:  22, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 126.238907, mean_q: 2.580889, mean_eps: 0.100000\n",
            "  43222/400000: episode: 43222, duration: 0.048s, episode steps:   1, steps per second:  21, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 92.961517, mean_q: 3.382264, mean_eps: 0.100000\n",
            "  43223/400000: episode: 43223, duration: 0.042s, episode steps:   1, steps per second:  24, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 0.000 [0.000, 0.000],  loss: 121.743591, mean_q: 3.719429, mean_eps: 0.100000\n",
            "  43224/400000: episode: 43224, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward: -25.000, mean reward: -25.000 [-25.000, -25.000], mean action: 1.000 [1.000, 1.000],  loss: 131.926102, mean_q: 4.048938, mean_eps: 0.100000\n",
            "  43225/400000: episode: 43225, duration: 0.057s, episode steps:   1, steps per second:  18, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 129.848434, mean_q: 2.367433, mean_eps: 0.100000\n",
            "  43226/400000: episode: 43226, duration: 0.045s, episode steps:   1, steps per second:  22, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 118.377640, mean_q: 5.593804, mean_eps: 0.100000\n",
            "  43227/400000: episode: 43227, duration: 0.057s, episode steps:   1, steps per second:  18, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 1.000 [1.000, 1.000],  loss: 187.135941, mean_q: 3.213130, mean_eps: 0.100000\n",
            "  43228/400000: episode: 43228, duration: 0.045s, episode steps:   1, steps per second:  22, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 141.106522, mean_q: 3.086081, mean_eps: 0.100000\n",
            "  43229/400000: episode: 43229, duration: 0.044s, episode steps:   1, steps per second:  23, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 138.855911, mean_q: 2.757775, mean_eps: 0.100000\n",
            "  43230/400000: episode: 43230, duration: 0.059s, episode steps:   1, steps per second:  17, episode reward: 22.000, mean reward: 22.000 [22.000, 22.000], mean action: 0.000 [0.000, 0.000],  loss: 117.855988, mean_q: 4.273865, mean_eps: 0.100000\n",
            "  43231/400000: episode: 43231, duration: 0.047s, episode steps:   1, steps per second:  21, episode reward:  1.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 2.000 [2.000, 2.000],  loss: 123.643188, mean_q: 2.292616, mean_eps: 0.100000\n",
            "done, took 2083.446 seconds\n",
            "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
            "K/Aminev250/19-20-29/19-20-29.h5f\n",
            "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1a4FI2rkNpn"
      },
      "source": [
        "loss 200"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}